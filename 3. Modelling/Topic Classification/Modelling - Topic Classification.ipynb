{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee4612f-7e9e-4e00-b46f-119da8ee57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c96ff8-f6a3-45e5-b672-eeec64363032",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecaa2f3-8c00-443d-aa2f-c187d23b00f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>topic</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-18 21:56:20.798000</td>\n",
       "      <td>593731316</td>\n",
       "      <td>@DSisourath The Thameslink core between London...</td>\n",
       "      <td>sprinklr</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>acd7673f-e621-5f1a-d662-df278964a6ea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acd7673f-e621-5f1a-d662-df278964a6ea</td>\n",
       "      <td>Z003XDCS</td>\n",
       "      <td>True</td>\n",
       "      <td>service</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-13 07:31:53.122000</td>\n",
       "      <td>745583289520496640</td>\n",
       "      <td>@DulwichHistory Loving the complaint about peo...</td>\n",
       "      <td>sprinklr</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>5b92aba8-4b05-6c63-8485-e9c870742137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5b92aba8-4b05-6c63-8485-e9c870742137</td>\n",
       "      <td>Z003XDCS</td>\n",
       "      <td>True</td>\n",
       "      <td>delays</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-26 19:27:24.695000</td>\n",
       "      <td>303134761</td>\n",
       "      <td>@SW_Help .And yet you have no toilets on some ...</td>\n",
       "      <td>sprinklr</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>0a799c07-8b76-17ba-b840-e538d51e832d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0a799c07-8b76-17ba-b840-e538d51e832d</td>\n",
       "      <td>Z003XDCS</td>\n",
       "      <td>True</td>\n",
       "      <td>toilets</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-26 19:28:49.281000</td>\n",
       "      <td>303134761</td>\n",
       "      <td>@SW_Help you have no toilets on some of your t...</td>\n",
       "      <td>sprinklr</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>8b4d2a34-c4f0-0e19-4055-dfe4af5f0e14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8b4d2a34-c4f0-0e19-4055-dfe4af5f0e14</td>\n",
       "      <td>Z003XDCS</td>\n",
       "      <td>True</td>\n",
       "      <td>toilets</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-28 11:59:41.212000</td>\n",
       "      <td>56427671</td>\n",
       "      <td>@SpeedySticks007 @MrNeilJH @TLRailUK @christia...</td>\n",
       "      <td>sprinklr</td>\n",
       "      <td>en</td>\n",
       "      <td>-1.09125</td>\n",
       "      <td>50.79899</td>\n",
       "      <td>1fd08862-d8c7-0682-6b11-2603fba22d94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1fd08862-d8c7-0682-6b11-2603fba22d94</td>\n",
       "      <td>Z003XDCS</td>\n",
       "      <td>True</td>\n",
       "      <td>seats</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source_created_at           author_id  \\\n",
       "0  2020-09-18 21:56:20.798000           593731316   \n",
       "1  2020-10-13 07:31:53.122000  745583289520496640   \n",
       "2  2020-10-26 19:27:24.695000           303134761   \n",
       "3  2020-10-26 19:28:49.281000           303134761   \n",
       "4  2020-09-28 11:59:41.212000            56427671   \n",
       "\n",
       "                                                text    source language  \\\n",
       "0  @DSisourath The Thameslink core between London...  sprinklr       en   \n",
       "1  @DulwichHistory Loving the complaint about peo...  sprinklr       en   \n",
       "2  @SW_Help .And yet you have no toilets on some ...  sprinklr       en   \n",
       "3  @SW_Help you have no toilets on some of your t...  sprinklr       en   \n",
       "4  @SpeedySticks007 @MrNeilJH @TLRailUK @christia...  sprinklr       en   \n",
       "\n",
       "   longitude  latitude                                    id  source_id  \\\n",
       "0   -0.12574  51.50853  acd7673f-e621-5f1a-d662-df278964a6ea        NaN   \n",
       "1   -0.12574  51.50853  5b92aba8-4b05-6c63-8485-e9c870742137        NaN   \n",
       "2   -0.12574  51.50853  0a799c07-8b76-17ba-b840-e538d51e832d        NaN   \n",
       "3   -0.12574  51.50853  8b4d2a34-c4f0-0e19-4055-dfe4af5f0e14        NaN   \n",
       "4   -1.09125  50.79899  1fd08862-d8c7-0682-6b11-2603fba22d94        NaN   \n",
       "\n",
       "                               tweet_id   user_id  relevant    topic  \\\n",
       "0  acd7673f-e621-5f1a-d662-df278964a6ea  Z003XDCS      True  service   \n",
       "1  5b92aba8-4b05-6c63-8485-e9c870742137  Z003XDCS      True   delays   \n",
       "2  0a799c07-8b76-17ba-b840-e538d51e832d  Z003XDCS      True  toilets   \n",
       "3  8b4d2a34-c4f0-0e19-4055-dfe4af5f0e14  Z003XDCS      True  toilets   \n",
       "4  1fd08862-d8c7-0682-6b11-2603fba22d94  Z003XDCS      True    seats   \n",
       "\n",
       "   ground_truth sentiment  \n",
       "0          True  negative  \n",
       "1          True  negative  \n",
       "2          True  negative  \n",
       "3          True  negative  \n",
       "4          True   neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Quynh Pham/Desktop/PM/Dataset/tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6c8ab",
   "metadata": {},
   "source": [
    "# Remove unnecessary columns except 'text' & 'topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732b1fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>\" Govia Thameslink fined ¬£1m over passenger ki...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Congestion\" is NOT a reason for delay, it's a...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Govia Thameslink Railway (GTR) is facing a ¬£5...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Minor delays\" #thameslink https://t.co/G46OnR...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"My apologies passengers, we appear to be havi...</td>\n",
       "      <td>doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15076</th>\n",
       "      <td>üöÑ The new Thameslink trains use regenerative b...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15077</th>\n",
       "      <td>üöÑ ‚Ä¢Overground: minor delays Hackney Wick to St...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>üöÜ A fault on a train earlier today at City Tha...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15079</th>\n",
       "      <td>üöÜ An operational incident between Finsbury Par...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15080</th>\n",
       "      <td>üöá Service Alert - signal failure at Wembley Pa...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16949 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   topic\n",
       "15196  \" Govia Thameslink fined ¬£1m over passenger ki...    none\n",
       "25     \"Congestion\" is NOT a reason for delay, it's a...  delays\n",
       "26     \"Govia Thameslink Railway (GTR) is facing a ¬£5...  delays\n",
       "27     \"Minor delays\" #thameslink https://t.co/G46OnR...  delays\n",
       "28     \"My apologies passengers, we appear to be havi...   doors\n",
       "...                                                  ...     ...\n",
       "15076  üöÑ The new Thameslink trains use regenerative b...    none\n",
       "15077  üöÑ ‚Ä¢Overground: minor delays Hackney Wick to St...  delays\n",
       "15078  üöÜ A fault on a train earlier today at City Tha...  delays\n",
       "15079  üöÜ An operational incident between Finsbury Par...  delays\n",
       "15080  üöá Service Alert - signal failure at Wembley Pa...  delays\n",
       "\n",
       "[16949 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop other columns except Tweet Content and Sentiment\n",
    "\n",
    "data.drop(data.columns.difference(['text','topic']), axis=1, inplace=True)\n",
    "data.sort_values(by='text', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe0bf2-676b-4dee-bac5-4ff32e74dc9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove duplicate rows (i.e. same text & same topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de497894-750d-429e-89c4-83dfdb26418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows (same text, same topic):  238\n"
     ]
    }
   ],
   "source": [
    "# Show total number of duplicate rows \n",
    "# Keep 1 of the duplicates in the dataframe, anything else is flagged as duplicates \n",
    "# Hence, above is 320 (show all) and here is 218 (keep 1, flag the rest as duplicate) because some have 2 duplicates and some has 3 duplicates   \n",
    "\n",
    "print('Total duplicate rows (same text, same topic): ', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a264d56b-9245-490b-9807-eaa196f53c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>#Hernehill on the class 700 to #LondonVictoria...</td>\n",
       "      <td>air conditioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15202</th>\n",
       "      <td>#Hernehill on the class 700 to #LondonVictoria...</td>\n",
       "      <td>air conditioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>#TLUpdates - Following a road vehicle collidin...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>#TLUpdates - Following a road vehicle collidin...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>#TLUpdates - We thank you for your patience du...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16781</th>\n",
       "      <td>Train operator Govia Thameslink Railway has be...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15192</th>\n",
       "      <td>üè° Cricklewood Lane, Cricklewood, London, NW2Br...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15065</th>\n",
       "      <td>üè° Cricklewood Lane, Cricklewood, London, NW2Br...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>üì£ #NewInstruction!üè° #ForSale: Millway, #NW7A w...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15195</th>\n",
       "      <td>üì£ #NewInstruction!üè° #ForSale: Millway, #NW7A w...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text             topic\n",
       "77     #Hernehill on the class 700 to #LondonVictoria...  air conditioning\n",
       "15202  #Hernehill on the class 700 to #LondonVictoria...  air conditioning\n",
       "284    #TLUpdates - Following a road vehicle collidin...            delays\n",
       "283    #TLUpdates - Following a road vehicle collidin...            delays\n",
       "523    #TLUpdates - We thank you for your patience du...            delays\n",
       "...                                                  ...               ...\n",
       "16781  Train operator Govia Thameslink Railway has be...              none\n",
       "15192  üè° Cricklewood Lane, Cricklewood, London, NW2Br...              none\n",
       "15065  üè° Cricklewood Lane, Cricklewood, London, NW2Br...              none\n",
       "15072  üì£ #NewInstruction!üè° #ForSale: Millway, #NW7A w...              none\n",
       "15195  üì£ #NewInstruction!üè° #ForSale: Millway, #NW7A w...              none\n",
       "\n",
       "[360 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all duplicate rows in the entire dataset\n",
    "# duplicated() parameters:\n",
    "#    By default, keep = 'first': 1st of duplicated rows to be kept in the dataframe, the rest to be flagged as duplicates and show down here\n",
    "#    keep = 'last': last of duplicated rows to be kept in the dataframe, the rest to be flagged as duplicates and show down here\n",
    "#    keep = False: flag and show all duplicated rows (not keeping any rows in dataframe)\n",
    "\n",
    "data.loc[data.duplicated(keep = False),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0e5b06-c665-4935-8e07-735afc6ed791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that already flagged as duplicates (keep 1 row in the dataframe)\n",
    "# inplace=True: make changes to the origial DataFrame\n",
    "\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cee6bf7-e8ad-4081-ad1f-b0e53e03477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9b155-dd14-4072-b653-ea45bbdbe07a",
   "metadata": {},
   "source": [
    "# List duplicate tweet with different topics (for view, not treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf130a8-c5eb-403a-8534-3d06a34d6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of duplicate Tweet with different topics:  962\n"
     ]
    }
   ],
   "source": [
    "# how many duplicate Tweet remains in the dataset\n",
    "\n",
    "print('Total numbers of duplicate Tweet with different topics: ',data['text'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1f3744-ed80-4e58-bdcc-448ff69eefaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>#EastCroydon #LondonBridge #Victoria use https...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>#EastCroydon #LondonBridge #Victoria use https...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>#TLUpdates - If you are travelling on services...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>#TLUpdates - If you are travelling on services...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>#TLUpdates - Please allow extra time for your ...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>#TLUpdates - Please allow extra time for your ...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>#TLUpdates - Please listen carefully to statio...</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>#TLUpdates - Please listen carefully to statio...</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>#TLUpdates - Services are now able to travel o...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>#TLUpdates - Services are now able to travel o...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>#TLUpdates - Services remain subject to delays...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>#TLUpdates - Services remain subject to delays...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>#TLUpdates - Services which run between St Pan...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>#TLUpdates - Services which run between St Pan...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>#TLUpdates - Station managers and first aiders...</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>#TLUpdates - Station managers and first aiders...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>#TLUpdates remember where there‚Äôs a delay ther...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>#TLUpdates remember where there‚Äôs a delay ther...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>#Thameslink congratulations on the Cambridge t...</td>\n",
       "      <td>plugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>#Thameslink congratulations on the Cambridge t...</td>\n",
       "      <td>tables</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "67   #EastCroydon #LondonBridge #Victoria use https...   \n",
       "66   #EastCroydon #LondonBridge #Victoria use https...   \n",
       "309  #TLUpdates - If you are travelling on services...   \n",
       "310  #TLUpdates - If you are travelling on services...   \n",
       "357  #TLUpdates - Please allow extra time for your ...   \n",
       "356  #TLUpdates - Please allow extra time for your ...   \n",
       "370  #TLUpdates - Please listen carefully to statio...   \n",
       "371  #TLUpdates - Please listen carefully to statio...   \n",
       "382  #TLUpdates - Services are now able to travel o...   \n",
       "381  #TLUpdates - Services are now able to travel o...   \n",
       "410  #TLUpdates - Services remain subject to delays...   \n",
       "411  #TLUpdates - Services remain subject to delays...   \n",
       "433  #TLUpdates - Services which run between St Pan...   \n",
       "434  #TLUpdates - Services which run between St Pan...   \n",
       "444  #TLUpdates - Station managers and first aiders...   \n",
       "443  #TLUpdates - Station managers and first aiders...   \n",
       "545  #TLUpdates remember where there‚Äôs a delay ther...   \n",
       "546  #TLUpdates remember where there‚Äôs a delay ther...   \n",
       "623  #Thameslink congratulations on the Cambridge t...   \n",
       "622  #Thameslink congratulations on the Cambridge t...   \n",
       "\n",
       "                         topic  \n",
       "67   tickets/seat_reservations  \n",
       "66                      delays  \n",
       "309                     delays  \n",
       "310  tickets/seat_reservations  \n",
       "357  tickets/seat_reservations  \n",
       "356                     delays  \n",
       "370                    station  \n",
       "371                    service  \n",
       "382  tickets/seat_reservations  \n",
       "381                     delays  \n",
       "410                     delays  \n",
       "411  tickets/seat_reservations  \n",
       "433                     delays  \n",
       "434  tickets/seat_reservations  \n",
       "444                    station  \n",
       "443                     delays  \n",
       "545                     delays  \n",
       "546  tickets/seat_reservations  \n",
       "623                      plugs  \n",
       "622                     tables  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 20 rows that has duplicate Tweet with different topics\n",
    "# by default, only show the 1st row of duplicate and drop the last row of duplicate\n",
    "# if want to keep the last row instead, set the parameter to duplicate(keep = 'last')\n",
    "# if want to show both the duplicates, set the parameter to duplicate(False)\n",
    "\n",
    "data[data['text'].duplicated(keep=False)].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a1b0c",
   "metadata": {},
   "source": [
    "# Check missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa0c57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     False\n",
       "topic    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30625705-0b75-4ab7-b1de-0c1fc7c325ab",
   "metadata": {},
   "source": [
    "# Export dataset for topic to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "925b20ac-c17e-47cb-a5f9-51a224d22fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for Topic is  (16711, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset for Topic is ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c74cc51-7dc3-4354-8f90-b5c42939e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('topic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e62c86-37c5-4520-8708-92c1aadd7d59",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split data into training, test & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18d6a3c-c428-4c1f-b76e-d2f0d15c403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, test & validation sets with ratio 70-15-15\n",
    "# First, split dataset into traing & test (ratio 85-15) then split training sets into training & validation (70-15)\n",
    "# Target variable is sentiment\n",
    "# Return: X_train, X_test, X_val, y_train, y_test, y_val\n",
    "# Parameters:\n",
    "#    random_state: make sure to get the same 3 subsets everytime. Set to be any int values\n",
    "#    stratify = sentiment (since there was an imbalance in neg, neu and positive sentiments and we have to set this in order to keep the same ratio in our subsets)\n",
    "\n",
    "X = data['text'] #the entire dataframe without sentiment column\n",
    "y = data['topic'] # our target variable\n",
    "\n",
    "X_main, X_test, y_main, y_test = train_test_split(X,y,test_size = 0.15, random_state=2, stratify = y) #split datasset into main & test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=0.15, random_state=2, stratify = y_main) #split main into train & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd77d7dd-6667-425b-8cf0-628f2ee757b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set:\t\t 12073   12073\n",
      "Length of test set:\t\t 2507   2507\n",
      "Length of validation set:\t 2131   2131\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training set:\\t\\t\",len(X_train),\" \",len(y_train))\n",
    "print(\"Length of test set:\\t\\t\",len(X_test),\" \",len(y_test))\n",
    "print(\"Length of validation set:\\t\",len(X_val),\" \",len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577d78f-7ebb-45c4-b1d6-4d3486fcd27f",
   "metadata": {},
   "source": [
    "# Export training, validation & test sets to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2419f54a-c5d2-4504-8cfb-7f3500e47639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>@TLRailUK I‚Äôm trying to process a refund for t...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11692</th>\n",
       "      <td>Another damning indictment on @TLRailUK on the...</td>\n",
       "      <td>toilets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>@TLRailUK @SouthernRailUK By severely reduced ...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8307</th>\n",
       "      <td>@TLRailUK been waiting outside Dartford on the...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>(Thameslink Update) 18:37 St Albans City to Su...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15621</th>\n",
       "      <td>@TLRailUK Good morning! Just want to notify yo...</td>\n",
       "      <td>vandalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>@TLRailUK All the displays screens in the carr...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13029</th>\n",
       "      <td>Please can you turn the heating off @TLRailUK ...</td>\n",
       "      <td>hvac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>@TLRailUK beyond pitiful. Told to go to platfo...</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>Yesterday was a nightmare getting home from Br...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12073 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      topic\n",
       "6646   @TLRailUK I‚Äôm trying to process a refund for t...     delays\n",
       "11692  Another damning indictment on @TLRailUK on the...    toilets\n",
       "4981   @TLRailUK @SouthernRailUK By severely reduced ...     delays\n",
       "8307   @TLRailUK been waiting outside Dartford on the...     delays\n",
       "1323   (Thameslink Update) 18:37 St Albans City to Su...     delays\n",
       "...                                                  ...        ...\n",
       "15621  @TLRailUK Good morning! Just want to notify yo...  vandalism\n",
       "5348   @TLRailUK All the displays screens in the carr...       none\n",
       "13029  Please can you turn the heating off @TLRailUK ...       hvac\n",
       "8308   @TLRailUK beyond pitiful. Told to go to platfo...    station\n",
       "14348  Yesterday was a nightmare getting home from Br...     delays\n",
       "\n",
       "[12073 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame([X_train, y_train]).T\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c1c1d20-4547-492a-84cd-8b39723ed5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15444</th>\n",
       "      <td>@SouthernRailUK @southern @TLRailUK There you ...</td>\n",
       "      <td>tickets/seat_reservations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>@TLRailUK does your air system bring in fresh ...</td>\n",
       "      <td>air conditioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>@LaraLipsey @tlupdates @TLRailUK They‚Äôve obvio...</td>\n",
       "      <td>hvac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>(Thameslink Update)  18:52 St Albans City to S...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>@TLRailUK @thetrainline Thank you for letting ...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>@TLRailUK There isn‚Äôt any seats left on this t...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16585</th>\n",
       "      <td>In case those affected by this had not seen th...</td>\n",
       "      <td>train_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>@JillySueD @TLRailUK Couldn't spot any numbers...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>1648 Grand Central train to Sunderland: On tim...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13360</th>\n",
       "      <td>TRAVEL: 15 minute delays on @SouthernRailUK @T...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "15444  @SouthernRailUK @southern @TLRailUK There you ...   \n",
       "8504   @TLRailUK does your air system bring in fresh ...   \n",
       "3447   @LaraLipsey @tlupdates @TLRailUK They‚Äôve obvio...   \n",
       "797    (Thameslink Update)  18:52 St Albans City to S...   \n",
       "5272   @TLRailUK @thetrainline Thank you for letting ...   \n",
       "...                                                  ...   \n",
       "7597   @TLRailUK There isn‚Äôt any seats left on this t...   \n",
       "16585  In case those affected by this had not seen th...   \n",
       "3310   @JillySueD @TLRailUK Couldn't spot any numbers...   \n",
       "2071   1648 Grand Central train to Sunderland: On tim...   \n",
       "13360  TRAVEL: 15 minute delays on @SouthernRailUK @T...   \n",
       "\n",
       "                           topic  \n",
       "15444  tickets/seat_reservations  \n",
       "8504            air conditioning  \n",
       "3447                        hvac  \n",
       "797                       delays  \n",
       "5272                      delays  \n",
       "...                          ...  \n",
       "7597                        none  \n",
       "16585              train_general  \n",
       "3310                      delays  \n",
       "2071                      delays  \n",
       "13360                     delays  \n",
       "\n",
       "[2507 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame([X_test, y_test]).T\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48a69727-8297-40b0-a688-6caab6c18ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>1820 Great Northern train to Moorgate: expecte...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>@TLRailUK waiting for a train to go into the s...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>@LutonTown @TLRailUK Hi Luton town any chance ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>@SteveWhiteRail @HPDCommuters @TLRailUK @grant...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>@TLRailUK cancelled four stops on the train we...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197</th>\n",
       "      <td>Govia Thameslink Railway has announced that Lu...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>2020 LNER train to Kings Cross: Delayed - plat...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>@TLRailUK @nationalrailenq Bedford Station - t...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>@TLRailUK @TfL @NetworkRailSE I would love it ...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13590</th>\n",
       "      <td>Thameslink update: 08:07 Brighton to Cambridge...</td>\n",
       "      <td>delays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2131 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text   topic\n",
       "2166   1820 Great Northern train to Moorgate: expecte...  delays\n",
       "9559   @TLRailUK waiting for a train to go into the s...  delays\n",
       "3511   @LutonTown @TLRailUK Hi Luton town any chance ...    none\n",
       "4342   @SteveWhiteRail @HPDCommuters @TLRailUK @grant...   covid\n",
       "8391   @TLRailUK cancelled four stops on the train we...  delays\n",
       "...                                                  ...     ...\n",
       "12197  Govia Thameslink Railway has announced that Lu...    none\n",
       "2337   2020 LNER train to Kings Cross: Delayed - plat...  delays\n",
       "5211   @TLRailUK @nationalrailenq Bedford Station - t...  delays\n",
       "5092   @TLRailUK @TfL @NetworkRailSE I would love it ...  delays\n",
       "13590  Thameslink update: 08:07 Brighton to Cambridge...  delays\n",
       "\n",
       "[2131 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.DataFrame([X_val, y_val]).T\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7121834b-c852-430e-8c10-97bd8e354cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('topic_test.csv') \n",
    "#train.to_csv('topic_train.csv')\n",
    "#validation.to_csv('topic_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f125a7-888c-4061-9313-878c4352ef52",
   "metadata": {},
   "source": [
    "# Cleaning Tweet Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63063c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quynh Pham\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# load spacy English language model trained based on web and social media texts\n",
    "# add more stop words to the list of stop words list in spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.Defaults.stop_words |= {'thameslink','tlupdates','gtrailuk','tlrailuk','govia', 'gtr'}\n",
    "nlp.Defaults.stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78be719e-1416-4a4b-985e-15b49549cb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n",
      "{'does', 'keep', 'together', 'further', '‚Äôll', 'already', 'this', 'the', '‚Äòve', 'while', 'itself', 'below', 'seemed', 'became', 'mostly', 'though', 'between', 'which', 'tlupdates', 'whether', 'wherever', 'would', 'never', 'in', 'too', 'hereupon', 'thereafter', 'because', 'top', 'everywhere', 'somewhere', 'any', 'go', 'third', 'very', 'both', 'might', 'or', 'always', 'anyway', 'yet', 'own', 'there', 'elsewhere', 'ca', 'behind', 'same', 'cannot', 'latterly', 'she', \"n't\", 'towards', '‚Äôm', 'using', 'nevertheless', 'such', 'get', 'part', 'wherein', 'whatever', 'well', 'how', 'becoming', \"'s\", 'although', 'done', 'less', 'do', 'will', 'all', 'otherwise', 'empty', '‚Äôs', 'again', 'anyone', 'hereafter', 'ours', 'are', 'alone', 'many', 'please', 'seems', 'themselves', 'were', 'indeed', 'across', 'am', 'with', 'several', 'still', 'next', 'hereby', 'so', 'whole', 'either', '‚Äòs', 'myself', 'really', 'whose', 'what', '‚Äòm', 'anything', 'almost', 'whereas', 'everyone', 'above', 'when', 'nor', 'nothing', 'whereupon', 'everything', 'none', 'sometime', 'show', 'been', 'rather', 'on', 'name', 'neither', 'amount', 'nine', 'did', 'under', \"'m\", 'often', \"'ve\", 'along', 'nobody', 'thru', 'seem', 'become', \"'ll\", 'down', 'i', 'during', 'therefore', 'him', 'perhaps', 'you', \"'d\", 'beside', 'up', 'ourselves', 'enough', 'afterwards', 'serious', 'gtr', 'being', 'an', 'hence', 'into', 'seeming', 'have', 'some', 'them', 'yours', 'until', 'its', 'made', 'we', '‚Äôd', 'fifteen', 'within', 'onto', 'from', 'they', 'over', 'govia', 'as', 'quite', 'these', 'forty', 'his', 'former', 'off', 'is', 'herein', 'back', 'thereby', 'by', 'once', 'among', 'however', 'each', '‚Äôre', 'upon', 'he', 'moreover', 'be', 'meanwhile', 'whereby', 'something', 'last', 'should', 'through', 'sixty', 'after', 'thus', 'most', 'their', 'twelve', 'sometimes', 'your', '‚Äòll', 'except', 'move', 'ever', 'used', 'against', 'see', 'other', '‚Äôve', 'can', 'n‚Äôt', 'every', 'if', 'beyond', 'tlrailuk', 'besides', 'via', 'hers', 'whence', 'fifty', 'eleven', 'has', 'without', 'somehow', 'may', 'herself', 'say', 'was', 'her', 'whoever', 're', 'eight', 'front', 'n‚Äòt', 'who', 'per', 'few', 'another', 'full', 'regarding', 'four', 'whither', 'yourself', 'must', 'now', 'one', 'various', 'gtrailuk', 'anyhow', 'thameslink', 'two', 'to', 'whom', 'around', 'our', 'where', 'but', 'ten', 'someone', 'me', 'thereupon', 'those', 'it', 'a', 'even', 'others', 'five', 'thence', 'noone', 'nowhere', 'for', 'before', 'mine', 'least', 'that', 'could', 'only', 'whereafter', 'put', 'side', 'and', 'toward', 'bottom', 'becomes', 'make', 'about', 'give', 'had', 'out', 'latter', 'then', 'here', 'first', 'himself', 'much', 'since', 'anywhere', 'whenever', 'twenty', 'take', 'formerly', 'doing', 'also', 'us', 'my', 'namely', 'just', 'therein', 'call', 'at', 'three', 'yourselves', 'beforehand', 'no', 'throughout', 'of', 'six', 'else', 'than', 'more', 'unless', '‚Äòre', 'due', '‚Äòd', \"'re\", 'why', 'hundred', 'amongst'}\n"
     ]
    }
   ],
   "source": [
    "# Print the list of stop words\n",
    "STOP_WORDS\n",
    "\n",
    "print(len(STOP_WORDS))\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c691e3a-9d85-48d1-8918-9469860d0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean tweet content\n",
    "# Tweet will be cleaned by the following steps:\n",
    "# 1. Remove emoji\n",
    "# 2. Remove #thameslink, #TLUpdates, @gtrailuk, @TLRailUK\n",
    "# 3. Turn word to lowercase\n",
    "# 4. Remove Twitter @usernames\n",
    "# 5. Remove hyperlink\n",
    "# 6. Remove punctuations\n",
    "# return clean text\n",
    "\n",
    "def cleanText(text):\n",
    "    #create a list of emojis pattern\n",
    "    emoji_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   \"]+\", flags = re.UNICODE)\n",
    "    text = re.sub(emoji_pattern,'', text) #remove emoji    \n",
    "    text = re.sub(r'#thameslink','',text) #remove #thameslink\n",
    "    text = re.sub(r'#TLUpdates','',text) #remove #TLUpdates\n",
    "    text = re.sub(r'@gtrailuk','',text) #remove @gtrailuk\n",
    "    text = re.sub(r'@TLRailUK','',text) #remove @TLRailUK\n",
    "    \n",
    "    text = text.lower() #turn every capitalization to lowercase    \n",
    "    text = re.sub(r'@[A-Za-z0-9\\_]+','',text) #remove @usernames, format of a username: alphanumeric characters (letters A-Z, numbers 0-9) with the exception of underscores\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #remove hyperlink\n",
    "    text = re.sub(r'\\b\\d+\\b','',text) #remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]','',text) #remove punctuations\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e6261a5-30f5-4195-9453-f4f904e3dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweet content\n",
    "# Use for loop to run through every tweets in the clean dataset\n",
    "# Cleaning steps include:\n",
    "# 1. Basic clean (i.e. remove unnecessary emojis, patterns, punctuation...) using the cleanText function above\n",
    "# 2. Tokenization: break sentence into words\n",
    "# 3. Remove stop words\n",
    "# 4. Lemmatization: strip words down to its root/stem\n",
    "\n",
    "def cleanSentence(main_df):\n",
    "    df = main_df.copy()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        filter_sentence = []\n",
    "        sentence = cleanText(row['text']) # call our function above to clean user text\n",
    "        words = nltk.word_tokenize(sentence) # tokenization\n",
    "        words = [w for w in words if not w in STOP_WORDS] # stopwords removal\n",
    "        for word in words:\n",
    "            filter_sentence.append(lemmatizer.lemmatize(word)) # lemmatization\n",
    "        clean_sentence = ' '.join(str(x) for x in filter_sentence if not len(x) == 1)\n",
    "        df.at[index,'text'] = clean_sentence  \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
