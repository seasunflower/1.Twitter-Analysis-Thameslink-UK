{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee4612f-7e9e-4e00-b46f-119da8ee57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c96ff8-f6a3-45e5-b672-eeec64363032",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecaa2f3-8c00-443d-aa2f-c187d23b00f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⚠️ #TLUpdates - Due to a safety inspection of ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@TLRailUK On the announcement we were told tha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1418 Thameslink train to Horsham: On time - pl...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This morning's Thameslink train is covered in ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TLRailUK I think a bit before Mill Hill, but ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>@TLRailUK She was the ticket lady at Arlesey t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11374</th>\n",
       "      <td>@TLRailUK perhaps you could have your train dr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11375</th>\n",
       "      <td>1323 Great Northern train to Moorgate: Delayed...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>Now stuck at harpenden. Not meant to stop here...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>@TLRailUK Looks like, 6:44 is now gonna stop a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      ⚠️ #TLUpdates - Due to a safety inspection of ...  negative\n",
       "1      @TLRailUK On the announcement we were told tha...  negative\n",
       "2      1418 Thameslink train to Horsham: On time - pl...   neutral\n",
       "3      This morning's Thameslink train is covered in ...   neutral\n",
       "4      @TLRailUK I think a bit before Mill Hill, but ...  negative\n",
       "...                                                  ...       ...\n",
       "11373  @TLRailUK She was the ticket lady at Arlesey t...  positive\n",
       "11374  @TLRailUK perhaps you could have your train dr...  negative\n",
       "11375  1323 Great Northern train to Moorgate: Delayed...   neutral\n",
       "11376  Now stuck at harpenden. Not meant to stop here...  negative\n",
       "11377  @TLRailUK Looks like, 6:44 is now gonna stop a...  negative\n",
       "\n",
       "[11378 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('sentiment_train.csv', names=['index','text','sentiment'], header=0)\n",
    "train.drop('index', axis=1, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6563133a-dd0d-4b8d-bcdb-038f50b9b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What dirt does @GatwickExpress have on @TLRail...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@EmilyTrenouth @TLRailUK Can’t see a carriage ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TLRailUK The 18:57 Cambridge to KingsX was de...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@SouthernRailUK @TLRailUK @GatwickExpress @MET...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TLRailUK Thank you for coming back to me. It'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>@TLRailUK Thanks.......It said it arrived ? Ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>@TLRailUK Can anyone there explain to me why I...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2005 Thameslink train to Gatwick Airport: Dela...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>.@networkrail @TLRailUK which person designed ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>. @TLRailUK we're sorry your train was delay b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     What dirt does @GatwickExpress have on @TLRail...  negative\n",
       "1     @EmilyTrenouth @TLRailUK Can’t see a carriage ...   neutral\n",
       "2     @TLRailUK The 18:57 Cambridge to KingsX was de...  negative\n",
       "3     @SouthernRailUK @TLRailUK @GatwickExpress @MET...   neutral\n",
       "4     @TLRailUK Thank you for coming back to me. It'...  negative\n",
       "...                                                 ...       ...\n",
       "2003  @TLRailUK Thanks.......It said it arrived ? Ca...  negative\n",
       "2004  @TLRailUK Can anyone there explain to me why I...   neutral\n",
       "2005  2005 Thameslink train to Gatwick Airport: Dela...   neutral\n",
       "2006  .@networkrail @TLRailUK which person designed ...  negative\n",
       "2007  . @TLRailUK we're sorry your train was delay b...  negative\n",
       "\n",
       "[2008 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.read_csv('sentiment_validation.csv', names=['index','text','sentiment'], header=0)\n",
    "validation.drop('index', axis=1, inplace=True)\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f30041-a90e-456c-8e63-bd2e6fead073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#TLUpdates - We have been advised by our colle...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@TLRailUK Aiming ... like chucking a hot dog u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long time since I’ve had to get a @TLRailUK tr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@thomasbrake @TLRailUK Can I ask for your view...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TLRailUK how is it even possible for you to c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>⚠️ #TLUpdates - Services are beginning to retu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>⚠️#TLUpdates - Train services running through ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>@LiveCommute @tlupdates @WorkerRailway @SaaSyS...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>@TLRailUK Hey, how do I do the ‘return unused ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>@TLRailUK @StPancrasInt SCREECHING is an excel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     #TLUpdates - We have been advised by our colle...   neutral\n",
       "1     @TLRailUK Aiming ... like chucking a hot dog u...  negative\n",
       "2     Long time since I’ve had to get a @TLRailUK tr...  negative\n",
       "3     @thomasbrake @TLRailUK Can I ask for your view...   neutral\n",
       "4     @TLRailUK how is it even possible for you to c...  negative\n",
       "...                                                 ...       ...\n",
       "2358  ⚠️ #TLUpdates - Services are beginning to retu...  negative\n",
       "2359  ⚠️#TLUpdates - Train services running through ...   neutral\n",
       "2360  @LiveCommute @tlupdates @WorkerRailway @SaaSyS...  negative\n",
       "2361  @TLRailUK Hey, how do I do the ‘return unused ...   neutral\n",
       "2362  @TLRailUK @StPancrasInt SCREECHING is an excel...  negative\n",
       "\n",
       "[2363 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('sentiment_test.csv', names=['index','text','sentiment'], header=0)\n",
    "test.drop('index', axis=1, inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb20e1-a6b3-431c-b657-3a80450214a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions for cleaning Tweet (clean text & clean sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2677c9f4-3c1d-420f-b2f1-cddf32cfcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy English language model trained based on web and social media texts\n",
    "# add more stop words to the list of stop words list in spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp.Defaults.stop_words |= {'thameslink','tlupdates','gtrailuk','tlrailuk','govia', 'gtr'}\n",
    "nlp.Defaults.stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e60922a-fd59-40f1-89f8-6d4bc7657d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n",
      "{'ourselves', '’m', 'ten', 'gtr', '‘s', 'around', 'ever', 'whereas', 'are', 'eleven', 'further', 'n’t', 'moreover', 'seemed', 'go', 'whenever', 'see', 'amongst', 'gtrailuk', '’re', 'myself', 'throughout', 'else', 'though', 'against', 'using', 'beforehand', 'still', 'herein', 'been', 'even', 'always', 'very', 'me', 'his', 'via', 'five', 'say', 'thameslink', 'last', 'nor', 're', 'much', 'afterwards', 'seem', 'her', 'hereafter', 'to', 'by', 'therein', 'was', 'get', 'every', 'it', 'towards', 'within', \"'ve\", \"'s\", 'now', 'whom', \"'d\", '’ll', 'four', 'unless', 'whereafter', 'same', 'nothing', 'whereby', 'hundred', 'everything', 'please', 'so', 'across', 'he', 'up', 'keep', 'other', 'becomes', 'has', 'which', 'what', 'cannot', 'full', 'side', 'everyone', 'whose', 'while', 'latterly', \"'re\", 'or', 'latter', 'that', 'whoever', 'if', 'this', 'down', 'seeming', '‘re', 'less', 'more', 'among', 'amount', 'nevertheless', 'their', 'after', 'least', 'you', 'never', 'can', 'both', 'well', 'rather', \"'ll\", 'thereby', 'am', 'whatever', 'did', 'anyway', 'perhaps', 'seems', 'have', 'third', 'in', 'thus', 'no', 'former', 'nobody', 'twenty', 'under', \"n't\", 'except', 'yet', 'eight', 'once', 'three', 'wherever', 'must', 'bottom', 'themselves', 'own', 'beyond', 'since', 'next', 'regarding', 'itself', 'done', 'as', 'indeed', 'together', 'namely', 'above', 'back', 'none', 'should', 'due', 'only', 'made', 'one', 'himself', 'thereupon', 'besides', 'than', 'various', 'almost', 'already', 'had', 'six', 'become', 'who', 'over', 'the', 'another', 'first', 'thence', 'although', 'herself', 'neither', 'few', 'many', 'we', 'could', 'per', 'mine', 'whole', 'be', 'whether', 'n‘t', 'without', 'sometime', 'however', 'formerly', 'either', 'yourselves', 'mostly', '‘ll', 'between', 'here', 'show', 'hereupon', 'yourself', 'top', 'there', 'twelve', 'us', 'thereafter', 'wherein', 'sixty', 'nowhere', 'nine', 'through', 'may', 'our', 'quite', 'about', 'of', 'thru', '’d', 'also', 'along', 'sometimes', 'empty', 'beside', '‘m', 'anyhow', 'with', 'and', 'do', 'move', 'then', 'at', 'others', 'those', 'whereupon', 'she', 'noone', 'were', 'enough', 'hers', 'serious', 'doing', 'somehow', 'why', '’s', 'put', 'below', 'off', 'just', 'anything', 'where', 'front', 'upon', 'elsewhere', 'for', 'somewhere', 'otherwise', 'becoming', 'became', 'from', 'all', 'each', 'several', 'fifteen', 'whence', 'make', 'tlupdates', 'is', 'ours', 'meanwhile', 'them', 'does', 'my', 'take', 'name', 'onto', 'whither', 'but', 'any', 'might', 'yours', 'into', 'alone', 'again', 'because', 'fifty', 'your', 'everywhere', 'these', 'behind', 'give', 'until', 'being', 'before', 'hereby', 'tlrailuk', 'would', 'out', 'how', 'hence', 'most', '’ve', \"'m\", 'forty', 'ca', 'him', 'anyone', 'govia', '‘ve', 'used', 'toward', '‘d', 'when', 'i', 'its', 'call', 'too', 'anywhere', 'two', 'often', 'some', 'something', 'a', 'someone', 'will', 'they', 'on', 'part', 'an', 'really', 'therefore', 'during', 'such'}\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS\n",
    "\n",
    "print(len(STOP_WORDS))\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2230ac4d-b36f-445f-8011-fb2787cbadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean tweet content\n",
    "# Tweet will be cleaned by the following steps:\n",
    "# 1. Remove emoji\n",
    "# 2. Remove #thameslink, #TLUpdates, @gtrailuk, @TLRailUK\n",
    "# 3. Turn word to lowercase\n",
    "# 4. Remove Twitter @usernames\n",
    "# 5. Remove hyperlink\n",
    "# 6. Remove punctuations\n",
    "# return clean text\n",
    "\n",
    "def cleanText(text):\n",
    "    #create a list of emojis pattern\n",
    "    emoji_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   \"]+\", flags = re.UNICODE)\n",
    "    text = re.sub(emoji_pattern,'', text) #remove emoji    \n",
    "    text = re.sub(r'#thameslink','',text) #remove #thameslink\n",
    "    text = re.sub(r'#TLUpdates','',text) #remove #TLUpdates\n",
    "    text = re.sub(r'@gtrailuk','',text) #remove @gtrailuk\n",
    "    text = re.sub(r'@TLRailUK','',text) #remove @TLRailUK\n",
    "    \n",
    "    text = text.lower() #turn every capitalization to lowercase    \n",
    "    text = re.sub(r'@[A-Za-z0-9\\_]+','',text) #remove @usernames, format of a username: alphanumeric characters (letters A-Z, numbers 0-9) with the exception of underscores\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #remove hyperlink\n",
    "    text = re.sub(r'\\b\\d+\\b','',text) #remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]','',text) #remove punctuations\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db560345-1449-4a64-8ba4-edebe75c40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweet content\n",
    "# Use for loop to run through every tweets in the clean dataset\n",
    "# Cleaning steps include:\n",
    "# 1. Basic clean (i.e. remove unnecessary emojis, patterns, punctuation...) using the cleanText function above\n",
    "# 2. Tokenization: break sentence into words\n",
    "# 3. Remove stop words\n",
    "# 4. Lemmatization: strip words down to its root/stem\n",
    "# return a DataFrame with clean words\n",
    "\n",
    "def cleanSentence(main_df):\n",
    "    df = main_df.copy()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        filter_sentence = []\n",
    "        sentence = cleanText(row['text']) # call our function above to clean user text\n",
    "        words = nltk.word_tokenize(sentence) # tokenization\n",
    "        words = [w for w in words if not w in STOP_WORDS] # stopwords removal\n",
    "        for word in words:\n",
    "            filter_sentence.append(lemmatizer.lemmatize(word)) # lemmatization\n",
    "        clean_sentence = ' '.join(str(x) for x in filter_sentence if not len(x) == 1)\n",
    "        df.at[index,'text'] = clean_sentence  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59214de6-34db-4a7a-8b5e-11ab4a825dc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SENTIMENT ANALYSIS WITH LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afb6df-2f19-4920-ad02-ccf163155967",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataset for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eede4b1-70ca-48ff-9bda-7b5e0e70f2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>safety inspection track undertaken network rai...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announcement told driver hadnt shown cancel tr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train horsham time plat train peterborough del...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning train covered graffiti read come dosse...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think bit mill hill definitely got worse peopl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>ticket lady arlesey ended dealing literally tr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11374</th>\n",
       "      <td>train driver passenger informed running lbg tb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11375</th>\n",
       "      <td>great northern train moorgate delayed plat tra...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>stuck harpenden not meant stop door didnt open...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>look like gon na stop stop announcement tho to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      safety inspection track undertaken network rai...  negative\n",
       "1      announcement told driver hadnt shown cancel tr...  negative\n",
       "2      train horsham time plat train peterborough del...   neutral\n",
       "3      morning train covered graffiti read come dosse...   neutral\n",
       "4      think bit mill hill definitely got worse peopl...  negative\n",
       "...                                                  ...       ...\n",
       "11373  ticket lady arlesey ended dealing literally tr...  positive\n",
       "11374  train driver passenger informed running lbg tb...  negative\n",
       "11375  great northern train moorgate delayed plat tra...   neutral\n",
       "11376  stuck harpenden not meant stop door didnt open...  negative\n",
       "11377  look like gon na stop stop announcement tho to...  negative\n",
       "\n",
       "[11378 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right now, the model perform much better on unclean text. Clean text can always been done by uncheck the hastags below\n",
    "\n",
    "train_lr = train.copy()\n",
    "train_lr = cleanSentence(train_lr)\n",
    "train_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767ba7f0-d7fe-4d99-9cc7-e725a11ed258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advised colleague network rail point failure s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aiming like chucking hot dog toilet roll tube ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long time ive train late filthy got seat look ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask view mr brake 1m fine given railway death ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>possible compound today delay having train pla...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>service beginning return normal running networ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>train service running station cancelled delaye...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>train leave minute late impunity time cant hel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>hey return unused ticket cancellation fee appl...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>screeching excellent word sound train arrive d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     advised colleague network rail point failure s...   neutral\n",
       "1     aiming like chucking hot dog toilet roll tube ...  negative\n",
       "2     long time ive train late filthy got seat look ...  negative\n",
       "3     ask view mr brake 1m fine given railway death ...   neutral\n",
       "4     possible compound today delay having train pla...  negative\n",
       "...                                                 ...       ...\n",
       "2358  service beginning return normal running networ...  negative\n",
       "2359  train service running station cancelled delaye...   neutral\n",
       "2360  train leave minute late impunity time cant hel...  negative\n",
       "2361  hey return unused ticket cancellation fee appl...   neutral\n",
       "2362  screeching excellent word sound train arrive d...  negative\n",
       "\n",
       "[2363 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lr = test.copy()\n",
    "test_lr = cleanSentence(test_lr)\n",
    "test_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a6365f-0950-4b54-9c75-7a336fc94f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dirt let dick tired commutingsucks</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant carriage number say carriage screen</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cambridge kingsx delayed 10mins announcement g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train running bridge directly littlehampton st...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank coming daft reason late stop order south...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>thanksit said arrived not delayed screen</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>explain dig travel card enter ticket number di...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>train gatwick airport delayed plat train bridg...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>person designed seat spike comfortable</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>sorry train delay minute cancelling wait minut...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0                    dirt let dick tired commutingsucks  negative\n",
       "1              cant carriage number say carriage screen   neutral\n",
       "2     cambridge kingsx delayed 10mins announcement g...  negative\n",
       "3     train running bridge directly littlehampton st...   neutral\n",
       "4     thank coming daft reason late stop order south...  negative\n",
       "...                                                 ...       ...\n",
       "2003           thanksit said arrived not delayed screen  negative\n",
       "2004  explain dig travel card enter ticket number di...   neutral\n",
       "2005  train gatwick airport delayed plat train bridg...   neutral\n",
       "2006             person designed seat spike comfortable  negative\n",
       "2007  sorry train delay minute cancelling wait minut...  negative\n",
       "\n",
       "[2008 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_lr = validation.copy()\n",
    "validation_lr = cleanSentence(validation_lr)\n",
    "validation_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ffee37-2d1a-41b3-bb9e-7acb39f49ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr = train_lr['text']\n",
    "y_train_lr = train_lr['sentiment']\n",
    "\n",
    "X_test_lr = test_lr['text']\n",
    "y_test_lr = test_lr['sentiment'] \n",
    "\n",
    "X_val_lr = validation_lr['text']\n",
    "y_val_lr = validation_lr['sentiment'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1169c-f58c-4861-9c60-f83eacc530d9",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c447a10b-8d65-4743-8727-2704621e7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 1420)\n",
    "vectorizer.fit(X_train_lr)\n",
    "\n",
    "encoded_X_train = vectorizer.transform(X_train_lr)\n",
    "encoded_X_test = vectorizer.transform(X_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c592a3-fb05-4262-9be0-e2613b5ff073",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90af24d-01e9-4419-a816-740c384710d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=777)\n",
    "X_ROS, y_ROS = ros.fit_sample(encoded_X_train, y_train_lr)\n",
    "\n",
    "smote = SMOTE(random_state=777)\n",
    "X_smote, y_smote = smote.fit_sample(encoded_X_train, y_train_lr)\n",
    "\n",
    "smoteenn = SMOTEENN(random_state=777)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_sample(encoded_X_train, y_train_lr)\n",
    "\n",
    "smotetomek = SMOTETomek(random_state=777)\n",
    "X_smotetomek, y_smotetomek = smotetomek.fit_sample(encoded_X_train, y_train_lr)\n",
    "\n",
    "adasyn = ADASYN(random_state=777)\n",
    "X_adasyn, y_adasyn = adasyn.fit_sample(encoded_X_train, y_train_lr)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=777)\n",
    "X_RUS, y_RUS = rus.fit_sample(encoded_X_train, y_train_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee53ca-1d13-4739-ade1-a7b8c962f585",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelling & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bff7fb3-2c0c-4c04-be41-547cae85a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ROS:  0.6555226407109607\n",
      "Accuracy with SMOTE:  0.6546762589928058\n",
      "Accuracy with SMOTEENN:  0.39060516292848074\n",
      "Accuracy with SMOTETOMEK:  0.6563690224291155\n",
      "Accuracy with ADASYN:  0.6550994498518832\n",
      "Accuracy with RUS:  0.5078290308929327\n"
     ]
    }
   ],
   "source": [
    "# Models after balancing\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model1.fit(X_ROS, y_ROS)\n",
    "accuracy1 = model1.score(encoded_X_test, y_test_lr)\n",
    "print('Accuracy with ROS: ',accuracy1)\n",
    "\n",
    "model2 = LogisticRegression(max_iter=1000)\n",
    "model2.fit(X_smote, y_smote)\n",
    "accuracy2 = model2.score(encoded_X_test, y_test_lr)\n",
    "print('Accuracy with SMOTE: ',accuracy2)\n",
    "\n",
    "model3 = LogisticRegression(max_iter=1000)\n",
    "model3.fit(X_smoteenn, y_smoteenn)\n",
    "print('Accuracy with SMOTEENN: ',model3.score(encoded_X_test, y_test_lr))\n",
    "\n",
    "model4 = LogisticRegression(max_iter=1000)\n",
    "model4.fit(X_smotetomek, y_smotetomek)\n",
    "print('Accuracy with SMOTETOMEK: ',model4.score(encoded_X_test, y_test_lr))\n",
    "\n",
    "model5 = LogisticRegression(max_iter=1000)\n",
    "model5.fit(X_adasyn, y_adasyn)\n",
    "accuracy5 = model5.score(encoded_X_test, y_test_lr)\n",
    "print('Accuracy with ADASYN: ',accuracy5)\n",
    "\n",
    "model6 = LogisticRegression(max_iter=1000)\n",
    "model6.fit(X_RUS, y_RUS)\n",
    "print('Accuracy with RUS: ',model6.score(encoded_X_test, y_test_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87424b2f-a14b-4a55-b3c4-2817c61bdfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ROS:  0.6555226407109607\n",
      "Precision: 0.684\n",
      "Recall: 0.656\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          neutral  negative  positive\n",
      "neutral       572       268        25\n",
      "negative      470       958        36\n",
      "positive        6         9        19\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix in percentage\n",
      "\n",
      "           neutral  negative  positive\n",
      "neutral   0.545802  0.217004    0.3125\n",
      "negative  0.448473  0.775709    0.4500\n",
      "positive  0.005725  0.007287    0.2375\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model with ROS \n",
    "y_pred1 = model1.predict(encoded_X_test)\n",
    "print('Accuracy with ROS: ',accuracy1)\n",
    "#precision and recall\n",
    "print('Precision: %.3f' % precision_score(y_test_lr, y_pred1,average='weighted'))\n",
    "print('Recall: %.3f' % recall_score(y_test_lr, y_pred1,average='weighted'))\n",
    "\n",
    "#confusion matrix on test set\n",
    "cm = confusion_matrix(y_test_lr, y_pred1, labels=test.sentiment.unique())\n",
    "confusionMatrix_df = pd.DataFrame(cm, index=test.sentiment.unique(), columns=test.sentiment.unique())\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix\\n\")\n",
    "print (confusionMatrix_df)\n",
    "\n",
    "\n",
    "#confusion matrix in percentage %\n",
    "confusionMatrix_percenteage_df = confusionMatrix_df.copy()\n",
    "for i in confusionMatrix_percenteage_df:\n",
    "    confusionMatrix_percenteage_df[i]/=confusionMatrix_percenteage_df[i].sum()\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix in percentage\\n\")\n",
    "print (confusionMatrix_percenteage_df)\n",
    "print (\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b9771f-0c66-421b-885d-17a8d08e52a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SMOTE:  0.6546762589928058\n",
      "Precision with SMOTE: 0.682\n",
      "Recall with SMOTE: 0.655\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          neutral  negative  positive\n",
      "neutral       538       283        44\n",
      "negative      428       994        42\n",
      "positive        7        12        15\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix in percentage\n",
      "\n",
      "           neutral  negative  positive\n",
      "neutral   0.552929   0.21955  0.435644\n",
      "negative  0.439877   0.77114  0.415842\n",
      "positive  0.007194   0.00931  0.148515\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model with SMOTE \n",
    "y_pred2 = model2.predict(encoded_X_test)\n",
    "print('Accuracy with SMOTE: ',accuracy2)\n",
    "\n",
    "#precision and recall\n",
    "print('Precision with SMOTE: %.3f' % precision_score(y_test_lr, y_pred2,average='weighted'))\n",
    "print('Recall with SMOTE: %.3f' % recall_score(y_test_lr, y_pred2,average='weighted'))\n",
    "\n",
    "#confusion matrix on test set\n",
    "cm = confusion_matrix(y_test_lr, y_pred2, labels=test.sentiment.unique())\n",
    "confusionMatrix_df = pd.DataFrame(cm, index=test.sentiment.unique(), columns=test.sentiment.unique())\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix\\n\")\n",
    "print (confusionMatrix_df)\n",
    "\n",
    "#confusion matrix in percentage %\n",
    "confusionMatrix_percenteage_df = confusionMatrix_df.copy()\n",
    "for i in confusionMatrix_percenteage_df:\n",
    "    confusionMatrix_percenteage_df[i]/=confusionMatrix_percenteage_df[i].sum()\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix in percentage\\n\")\n",
    "print (confusionMatrix_percenteage_df)\n",
    "print (\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d60fcb7-c016-4187-98a7-c6bca8de7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with ADSYN:  0.6550994498518832\n",
      "Precision with ADASYN: 0.682\n",
      "Recall with ADASYN: 0.655\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          neutral  negative  positive\n",
      "neutral       551       272        42\n",
      "negative      443       982        39\n",
      "positive        8        11        15\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix in percentage\n",
      "\n",
      "           neutral  negative  positive\n",
      "neutral   0.549900  0.215020   0.43750\n",
      "negative  0.442116  0.776285   0.40625\n",
      "positive  0.007984  0.008696   0.15625\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model with ADASYN \n",
    "y_pred5 = model5.predict(encoded_X_test)\n",
    "print('Accuracy with ADSYN: ',accuracy5)\n",
    "\n",
    "#precision and recall\n",
    "print('Precision with ADASYN: %.3f' % precision_score(y_test_lr, y_pred2,average='weighted'))\n",
    "print('Recall with ADASYN: %.3f' % recall_score(y_test_lr, y_pred2,average='weighted'))\n",
    "\n",
    "#confusion matrix on test set\n",
    "cm = confusion_matrix(y_test_lr, y_pred5, labels=test.sentiment.unique())\n",
    "confusionMatrix_df = pd.DataFrame(cm, index=test.sentiment.unique(), columns=test.sentiment.unique())\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix\\n\")\n",
    "print (confusionMatrix_df)\n",
    "\n",
    "#confusion matrix in percentage %\n",
    "confusionMatrix_percenteage_df = confusionMatrix_df.copy()\n",
    "for i in confusionMatrix_percenteage_df:\n",
    "    confusionMatrix_percenteage_df[i]/=confusionMatrix_percenteage_df[i].sum()\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix in percentage\\n\")\n",
    "print (confusionMatrix_percenteage_df)\n",
    "print (\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ceaf009-a0db-41ae-8fb2-dacf1016b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with class weight:  0.6618705035971223\n",
      "Precision with class weight: 0.695\n",
      "Recall with class weight: 0.662\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          neutral  negative  positive\n",
      "neutral       590       249        26\n",
      "negative      466       954        44\n",
      "positive        7         7        20\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix in percentage\n",
      "\n",
      "           neutral  negative  positive\n",
      "neutral   0.555033  0.205785  0.288889\n",
      "negative  0.438382  0.788430  0.488889\n",
      "positive  0.006585  0.005785  0.222222\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model without class weight balance\n",
    "model10 = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model10.fit(encoded_X_train, y_train_lr)\n",
    "y_pred10 = model10.predict(encoded_X_test)\n",
    "print('Accuracy with class weight: ',model10.score(encoded_X_test, y_test_lr))\n",
    "\n",
    "#precision and recall\n",
    "print('Precision with class weight: %.3f' % precision_score(y_test_lr, y_pred10,average='weighted'))\n",
    "print('Recall with class weight: %.3f' % recall_score(y_test_lr, y_pred10,average='weighted'))\n",
    "\n",
    "#confusion matrix on test set\n",
    "cm = confusion_matrix(y_test_lr, y_pred10, labels=test.sentiment.unique())\n",
    "confusionMatrix_df = pd.DataFrame(cm, index=test.sentiment.unique(), columns=test.sentiment.unique())\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix\\n\")\n",
    "print (confusionMatrix_df)\n",
    "\n",
    "#confusion matrix in percentage %\n",
    "confusionMatrix_percenteage_df = confusionMatrix_df.copy()\n",
    "for i in confusionMatrix_percenteage_df:\n",
    "    confusionMatrix_percenteage_df[i]/=confusionMatrix_percenteage_df[i].sum()\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix in percentage\\n\")\n",
    "print (confusionMatrix_percenteage_df)\n",
    "print (\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7709eec-43c6-49f5-bbd7-21420c4f62ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without balancing:  0.7046127803639441\n",
      "Precision without balancing: 0.699\n",
      "Recall without balancing: 0.705\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          neutral  negative  positive\n",
      "neutral       482       381         2\n",
      "negative      287      1174         3\n",
      "positive       12        13         9\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix in percentage\n",
      "\n",
      "           neutral  negative  positive\n",
      "neutral   0.617157  0.242985  0.142857\n",
      "negative  0.367478  0.748724  0.214286\n",
      "positive  0.015365  0.008291  0.642857\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model without balancing\n",
    "model11 = LogisticRegression(max_iter=1000)\n",
    "model11.fit(encoded_X_train, y_train_lr)\n",
    "y_pred11 = model11.predict(encoded_X_test)\n",
    "print('Accuracy without balancing: ',model11.score(encoded_X_test, y_test_lr))\n",
    "#precision and recall\n",
    "print('Precision without balancing: %.3f' % precision_score(y_test_lr, y_pred11,average='weighted'))\n",
    "print('Recall without balancing: %.3f' % recall_score(y_test_lr, y_pred11,average='weighted'))\n",
    "\n",
    "#confusion matrix on test set\n",
    "cm = confusion_matrix(y_test_lr, y_pred11, labels=test.sentiment.unique())\n",
    "confusionMatrix_df = pd.DataFrame(cm, index=test.sentiment.unique(), columns=test.sentiment.unique())\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix\\n\")\n",
    "print (confusionMatrix_df)\n",
    "\n",
    "#confusion matrix in percentage %\n",
    "confusionMatrix_percenteage_df = confusionMatrix_df.copy()\n",
    "for i in confusionMatrix_percenteage_df:\n",
    "    confusionMatrix_percenteage_df[i]/=confusionMatrix_percenteage_df[i].sum()\n",
    "print (\"-\"*60)\n",
    "print (\"Confusion Matrix in percentage\\n\")\n",
    "print (confusionMatrix_percenteage_df)\n",
    "print (\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823bbb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf2963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
